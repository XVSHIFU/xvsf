---
title: "信息标记与提取方法"
date: 2026-01-26T10:00:00+08:00
categories:
  - "Python网络爬虫与信息提取"
---



# 信息标记的三种形式
## 信息的标记
<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502097843-fc218869-c6a1-4e6e-a8bc-312145705376.png)

标记后的信息可形成信息组织结构，增加了信息维度

标记的结构与信息一样具有重要价值

标记后的信息可用于通信、存储或展示

标记后的信息更利于程序理解和运用





## HTML 的信息标记


<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502151753-16ca7a71-2f46-43d3-9d7c-66f9db01ee44.png)

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502161158-a032bc7c-10b9-45a0-9966-fd04a2b622d3.png)





## 信息标记的三种形式
### XML
eXtensible Markup Language

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502226988-893a9671-5af0-4d13-89bd-1df0d2669f3a.png)



<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502233592-b26d7385-5981-430b-98f5-233b77f112f1.png)



<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502246725-6a1f8897-8992-40e5-8fb2-baa82386b99c.png)















### JSON
JavsScript Object Notation

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502262201-278ded8f-b958-4382-acce-d42e03111352.png)

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502266894-e32e86b6-2fbc-4146-bab6-3b869200b0c8.png)

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502274111-0cec727a-6a6c-4d07-95c7-2c618d0bcc0e.png)



<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502291407-761c6541-f372-4964-beb2-edb6d71cc247.png)



### YAML
YAML Ain't Markup Language

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502334708-90c85bd0-561c-4a64-a8fa-e0ce0226a5b3.png)

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502340485-c5991d8e-e162-4e8f-aeea-eb9acd200b15.png)

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502346473-0ce385e3-563c-4d13-9bd7-085e86a0bf2e.png)

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502352294-5d1e6a52-9c57-4d8a-a3ad-248992ac2fb4.png)



<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502357713-542564de-203e-42bd-abf8-b9cae63b6c68.png)





### 小结&比较
#### XML：
```xml
<name>...</name>
<name/>
<!-- -->
```

```xml
<person>
  <firstName>Tian</firstName>
  <lastName>Song</lastName>
  <address>
    <streetAddr>中关村南大街5号</streetAddr>
    <city>北京市</city>
    <zipcode>100081</zipcode>
  </address>
  <prof>Computer System</prof><prof>Security</prof>
</person>

```

#### JSON:
```json
"key" : "value"
"key" : ["value1", "value2"]
"key" : {"subkey" : "subvalue"}
```

```json
{
  "firstName” : "Tian” ,
  "lastName” : "Song” ,
  "address” : {
                "streetAddr” : "中关村南大街5号” ,
                "city" : "北京市” ,
                "zipcode” : "100081”
              } ,
  "prof” : [ "Computer System” , "Security” ]
}
```

#### YAML:
```yaml
key : value
key : #Comment
-value1
-value2
key :
  subkey :subvalue
```

```yaml
firstName : Tian
lastName : Song
address:
    streetAddr : 中关村南大街5号
    city: 北京市
    zipcode: 100081
prof:
‐Computer System
‐Security
```





#### 比较
<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502829858-59638c34-e59e-4a0c-9116-9a2de105c7e7.png)



<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769502839796-fba5ebc0-bb79-496c-999d-e41f1572167b.png)







# 信息提取的一般方法
## 方法一：完整解析信息的标记形式，再提取关键信息
**XML JSON YAML**

需要标记解析器，例如：bs4库的标签树遍历

优点：信息解析准确

缺点：提取过程繁琐，速度慢

## 方法二：无视标记形式，直接搜索关键信息
**搜索**

对信息的文本查找函数即可

优点：提取过程简洁，速度较快

缺点：提取结果准确性与信息内容相关



## 融合方法：结合形式解析与搜索方法，提取关键信息
**XML JSON YAML 搜索**

需要标记解析器及文本查找函数



## 实例：
提取 HTML 中所有 URL 链接

思路：1）搜索到所有`<a>`标签

    2）解析`<a>`标签格式，提取`href`后的链接内容



```python
import requests

r = requests.get("http://python123.io/ws/demo.html")
demo = r.text

from bs4 import BeautifulSoup
soup = BeautifulSoup(demo,"html.parser")
for link in soup.find_all('a'):
    print(link.get('href'))


http://www.icourse163.org/course/BIT-268001
http://www.icourse163.org/course/BIT-1001870001

```

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769503128358-a7e2871a-0fe6-431f-81ae-1e21f3148805.png)





## 基于 bs4 库的 HTML 内容查找方法
`<>.find_all(name, attrs, recursive, string, **kwargs)`

返回一个列表类型，存储查找的结果

+ `name`：对标签名称的检索字符串
+ `attrs`：对标签属性值的检索字符串，可标注属性检索
+ `recursive`：是否对子孙全部检索，默认True
+ `string`：`<>…</>`中字符串区域的检索字符串



```python
soup.find_all('a')
[<a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a>, <a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2">Advanced Python</a>]
soup.find_all(['a', 'b'])
[<b>The demo python introduces several python courses.</b>, <a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a>, <a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2">Advanced Python</a>]
for tag in soup.find_all(True):
    print(tag.name)

html
head
title
body
p
b
p
a
a
import re
for tag in soup.find_all(re.compile('b')):
    print(tag.name)

    
body
b


soup.find_all(id='link')
[]
soup.find_all(id=re.compile('link'))
[<a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a>, <a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2">Advanced Python</a>]



soup.find_all('a')
[<a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a>, <a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2">Advanced Python</a>]
soup.find_all('a', recursive=False)
[]



soup
<html><head><title>This is a python demo page</title></head>
<body>
<p class="title"><b>The demo python introduces several python courses.</b></p>
<p class="course">Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:

<a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a> and <a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2">Advanced Python</a>.</p>
</body></html>
soup.find_all(sring='Basic Python')
[]
soup.find_all(string='Basic Python')
['Basic Python']
soup.find_all(string=re.compile('python'))
['This is a python demo page', 'The demo python introduces several python courses.']

```



```python
<tag>(..)  等价于  <tag>.find_all(..)
soup(..)   等价于  soup.find_all(..)
```



<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769503951786-5bef9b80-0621-4b8e-945c-8ed34fd88dd9.png)











# 实例：”中国大学排名定向爬虫“


<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769504386437-bf73c685-9c92-41b7-9450-1db2f8573da3.png)



## 功能描述
输入：大学排名URL链接

输出：大学排名信息的屏幕输出（排名，大学名称，总分）

技术路线：requests‐bs4

定向爬虫：仅对输入URL进行爬取，不扩展爬取



## 定向爬虫可行性
<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769504437572-667b9c1a-9a1a-4caa-9282-f8cb16f7b6c0.png)





## 程序的结构设计
步骤1：从网络上获取大学排名网页内容			getHTMLText()

步骤2：提取网页内容中信息到合适的数据结构		fillUnivList()

步骤3：利用数据结构展示并输出结果			printUnivList()



## 实例编写
```python
import requests
from bs4 import BeautifulSoup
```

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769505176425-a8b0bac0-2733-40f3-a086-d528f24cd88c.png)





> 在课程中，排名网用的是 HTML 表格，而现在的排名网用的是 JSON 格式的，
>
> 所以我重新写一个代码
>

### 旧：
```python
#CrawUnivRankingA.py
import requests
from bs4 import BeautifulSoup
import bs4

def getHTMLText(url):
    try:
        r = requests.get(url, timeout=30)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text
    except:
        return ""

def fillUnivList(ulist, html):
    soup = BeautifulSoup(html, "html.parser")
    for tr in soup.find('tbody').children:
        if isinstance(tr, bs4.element.Tag):
            tds = tr('td')
            ulist.append([tds[0].string, tds[1].string, tds[3].string])

def printUnivList(ulist, num):
    print("{:^10}\t{:^6}\t{:^10}".format("排名","学校名称","总分"))
    for i in range(num):
        u=ulist[i]
        print("{:^10}\t{:^6}\t{:^10}".format(u[0],u[1],u[2]))
    
def main():
    uinfo = []
    url = 'http://www.zuihaodaxue.cn/zuihaodaxuepaiming2016.html'
    html = getHTMLText(url)
    fillUnivList(uinfo, html)
    printUnivList(uinfo, 20) # 20 univs
main()

```

```python
#CrawUnivRankingB.py
import requests
from bs4 import BeautifulSoup
import bs4

def getHTMLText(url):
    try:
        r = requests.get(url, timeout=30)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text
    except:
        return ""

def fillUnivList(ulist, html):
    soup = BeautifulSoup(html, "html.parser")
    for tr in soup.find('tbody').children:
        if isinstance(tr, bs4.element.Tag):
            tds = tr('td')
            ulist.append([tds[0].string, tds[1].string, tds[3].string])

def printUnivList(ulist, num):
    tplt = "{0:^10}\t{1:{3}^10}\t{2:^10}"
    print(tplt.format("排名","学校名称","总分",chr(12288)))
    for i in range(num):
        u=ulist[i]
        print(tplt.format(u[0],u[1],u[2],chr(12288)))
    
def main():
    uinfo = []
    url = 'http://www.zuihaodaxue.cn/zuihaodaxuepaiming2016.html'
    html = getHTMLText(url)
    fillUnivList(uinfo, html)
    printUnivList(uinfo, 20) # 20 univs
main()

```













### 新：
```python
import requests
from bs4 import BeautifulSoup

def getHTMLText(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }
    r = requests.get(url, headers=headers, timeout=30)
    r.raise_for_status()
    r.encoding = r.apparent_encoding
    return r.text


def fillUnivList(ulist, html):
    soup = BeautifulSoup(html, "html.parser")

    tbody = soup.find("tbody")
    if not tbody:
        print("未找到 tbody")
        return

    for tr in tbody.find_all("tr"):
        tds = tr.find_all("td")
        if len(tds) < 5:
            continue

        # ① 排名
        rank = tds[0].get_text(strip=True)

        # ② 学校名称（中文名）
        name_tag = tds[1].find("span", class_="name-cn")
        name = name_tag.get_text(strip=True) if name_tag else ""

        # ③ 总分
        score = tds[4].get_text(strip=True)

        ulist.append([rank, name, score])


def printUnivList(ulist, num):
    print("{:^8}\t{:^20}\t{:^8}".format("排名", "学校名称", "总分"))
    for u in ulist[:num]:
        print("{:^8}\t{:^20}\t{:^8}".format(u[0], u[1], u[2]))


def main():
    uinfo = []
    url = "https://www.shanghairanking.cn/rankings/bcur/2025"
    html = getHTMLText(url)
    fillUnivList(uinfo, html)
    printUnivList(uinfo, 20)


if __name__ == "__main__":
    main()

```



<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2026/png/52403351/1769506061988-936b6cb5-897d-46e5-beb4-578cef9c3d2b.png)







